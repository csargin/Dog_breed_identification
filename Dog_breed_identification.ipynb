{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "v6tbFti0gzdf",
        "kGRr5__sgthA",
        "hOQNpJTqjbqj",
        "QgwqMeFAjsDc",
        "hQk4AH61kOsw",
        "nfLjBKFokVZF",
        "0SG2BhRrkdAG",
        "NE1W3UlWkgtF",
        "U7WHsXyzqRWH",
        "jpEoATPT-aWz",
        "kurFfffG-eKf"
      ],
      "mount_file_id": "1hgFCJuF0FY8EnpAlPT96ggBguj4my3QK",
      "authorship_tag": "ABX9TyN91gftnFlwhGBAaTPpxisu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/csargin/Dog_breed_identification/blob/main/Dog_breed_identification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intro\n",
        "\n",
        "https://www.kaggle.com/competitions/dog-breed-identification\n",
        "\n",
        "You are provided with a training set and a test set of images of dogs. Each image has a filename that is its unique id. The dataset comprises 120 breeds of dogs. The goal is to create a classifier capable of determining a dog's breed from a photo."
      ],
      "metadata": {
        "id": "rqgS8zPslR0v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "v6tbFti0gzdf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8tqdztOtbtGA"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import image as mpimg\n",
        "\n",
        "import tensorflow as tf\n",
        "from skimage.transform import resize\n",
        "from keras.applications import MobileNetV2\n",
        "from keras.layers import GlobalAveragePooling2D, Dense\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing import image\n",
        "\n",
        "# import warnings\n",
        "import warnings\n",
        "# filter warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import os\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load dataset from kaggle"
      ],
      "metadata": {
        "id": "kGRr5__sgthA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#https://www.kaggle.com/discussions/general/74235\n",
        "\n",
        "! pip install -q kaggle\n",
        "\n",
        "! mkdir ~/.kaggle\n",
        "! touch ~/.kaggle/kaggle.json\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "# make new JSON file\n",
        "with open('/content/kaggle.json', 'w') as f:\n",
        "  text = '{\"username\":\"' + userdata.get(\"kaggle_username\") + '\",\"key\":\"' + userdata.get('kaggle_psw') + '\"}'\n",
        "  f.write(text)\n",
        "\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! kaggle datasets list"
      ],
      "metadata": {
        "id": "w7VG8ppqcLJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle competitions download -c 'dog-breed-identification'"
      ],
      "metadata": {
        "id": "JQ05vCSAcmnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip -o dog-breed-identification.zip -d dog-breed-identification # unzip in order to overwrite files"
      ],
      "metadata": {
        "id": "PiCGKtN-gKAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/content/dog-breed-identification/train'\n",
        "test_dir = '/content/dog-breed-identification/test'\n",
        "labels = pd.read_csv('/content/dog-breed-identification/labels.csv') # Load the labels"
      ],
      "metadata": {
        "id": "50E0V2wajA6V"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training images"
      ],
      "metadata": {
        "id": "hOQNpJTqjbqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first 5 train images and their labels\n",
        "print('Train Images:')\n",
        "for i in range(5):\n",
        "    # Get the image filename and label\n",
        "    filename = labels.iloc[i]['id'] + '.jpg'\n",
        "    label = labels.iloc[i]['breed']\n",
        "\n",
        "    # Load and display the image\n",
        "    img_path = os.path.join(train_dir, filename)\n",
        "    img = mpimg.imread(img_path)\n",
        "    plt.imshow(img)\n",
        "    plt.title(label)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "dNfGewpNiAac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test images"
      ],
      "metadata": {
        "id": "QgwqMeFAjsDc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first 5 test images\n",
        "print('Test Images:')\n",
        "for i in range(5):\n",
        "    # Get the image filename\n",
        "    filename = os.listdir(test_dir)[i]\n",
        "\n",
        "    # Load and display the image\n",
        "    img_path = os.path.join(test_dir, filename)\n",
        "    img = mpimg.imread(img_path)\n",
        "    plt.imshow(img)\n",
        "    plt.title(filename)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "e2C9HpjTjpK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sorting of Breeds"
      ],
      "metadata": {
        "id": "hQk4AH61kOsw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "breeds = sorted(labels['breed'].unique())\n",
        "num_classes = len(breeds)"
      ],
      "metadata": {
        "id": "Hb37FApbkSr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mapping func"
      ],
      "metadata": {
        "id": "nfLjBKFokVZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a mapping from breed to integer label\n",
        "breed_to_label = {breed: i for i, breed in enumerate(breeds)}"
      ],
      "metadata": {
        "id": "7X06PuV8kY6m"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Sizing"
      ],
      "metadata": {
        "id": "0SG2BhRrkdAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the image size and batch size\n",
        "img_size = 224\n",
        "batch_size = 16"
      ],
      "metadata": {
        "id": "64LdI9kxkeaN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "NE1W3UlWkgtF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_preprocess_image(img_path, label):\n",
        "    img = tf.io.read_file(img_path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, [img_size, img_size])\n",
        "    img = tf.cast(img, tf.float32) / 255.0\n",
        "\n",
        "    # One-hot encode the label\n",
        "    label = tf.one_hot(label, num_classes)\n",
        "\n",
        "    return img, label"
      ],
      "metadata": {
        "id": "NVq4pUNIkkLd"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(df, train_dir, batch_size):\n",
        "    filenames = df['id'].apply(lambda x: os.path.join(train_dir, f\"{x}.jpg\")).values\n",
        "    labels = df['breed'].map(breed_to_label).values\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
        "    dataset = dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    dataset = dataset.batch(batch_size).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "Cc53ACY3koc-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MobileNetV2 architecture"
      ],
      "metadata": {
        "id": "U7WHsXyzqRWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = MobileNetV2(weights='imagenet', include_top=False)"
      ],
      "metadata": {
        "id": "qG7_7SAwtFd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Activation Func"
      ],
      "metadata": {
        "id": "jpEoATPT-aWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a global average pooling layer, followed by a dense layer with softmax activation\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "# Create a new model with the added layers\n",
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ],
      "metadata": {
        "id": "0t5NAzNu-cAP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelling"
      ],
      "metadata": {
        "id": "kurFfffG-eKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze the base model layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the model using the Adam optimizer and categorical crossentropy loss\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "qaiIGKdy-gF9"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the number of batches per epoch\n",
        "batches_per_epoch = math.ceil(len(labels) / batch_size)\n",
        "\n",
        "\n",
        "# Train the model for 10 epochs using tf.data.Dataset\n",
        "for epoch in range(10):\n",
        "    print('Epoch', epoch + 1)\n",
        "\n",
        "    # Create a progress bar object for this epoch\n",
        "    pbar = tqdm(total=batches_per_epoch)\n",
        "\n",
        "    # Shuffle the data\n",
        "    labels = labels.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "    # Load and preprocess the data using tf.data.Dataset\n",
        "    dataset = create_dataset(labels, train_dir, batch_size)\n",
        "\n",
        "    # Train the model on the dataset\n",
        "    for x_batch, y_batch in dataset:\n",
        "        model.train_on_batch(x_batch, y_batch.numpy())  # Convert y_batch to numpy array\n",
        "\n",
        "        # Update the progress bar\n",
        "        pbar.update(1)\n",
        "    pbar.close()"
      ],
      "metadata": {
        "id": "YNfeaSwb-lnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_filenames = os.listdir(test_dir)\n",
        "\n",
        "# Create a function to load and preprocess a test image\n",
        "def load_and_preprocess_test_image(img_path):\n",
        "    img = tf.io.read_file(img_path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, [img_size, img_size])\n",
        "    img = tf.cast(img, tf.float32) / 255.0\n",
        "    return img\n",
        "\n",
        "# Create a list to store the predictions\n",
        "predictions_list = []\n",
        "\n",
        "# Load and preprocess the test data and make predictions\n",
        "for filename in tqdm(test_filenames):\n",
        "    img_path = os.path.join(test_dir, filename)\n",
        "    img = load_and_preprocess_test_image(img_path)\n",
        "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
        "    prediction = model.predict(img)\n",
        "    predicted_label = breeds[np.argmax(prediction)]  # Convert prediction to label\n",
        "    predictions_list.append((filename.split('.')[0], predicted_label))\n",
        "\n",
        "# Create a DataFrame from the list of predictions\n",
        "submission_df = pd.DataFrame(predictions_list, columns=['id', 'breed'])\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "submission_df.to_csv('Dog_breed_Submission.csv', index=False)"
      ],
      "metadata": {
        "id": "Y83vWHPP-qd5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}